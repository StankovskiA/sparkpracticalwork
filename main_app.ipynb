{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session start and Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"DataLoadingExample\").getOrCreate()\n",
    "\n",
    "# Get the input data location from the command line or configuration\n",
    "input_data_location = \"data/1987.csv\"\n",
    "\n",
    "# Load the data into a PySpark DataFrame\n",
    "df = spark.read.csv(input_data_location, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Year' has only one unique value\n",
      "Column 'TailNum' has only one unique value\n",
      "Column 'TaxiOut' has only one unique value\n",
      "Column 'CancellationCode' has only one unique value\n",
      "Numerical Columns: ['Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime', 'CRSArrTime', 'FlightNum', 'CRSElapsedTime', 'DepDelay', 'Distance', 'Cancelled']\n",
      "Categorical Columns: ['UniqueCarrier', 'Origin', 'Dest']\n"
     ]
    }
   ],
   "source": [
    "# List of columns to be removed\n",
    "columns_to_remove = ['ArrTime', 'ActualElapsedTime', 'AirTime', 'TaxiIn', 'Diverted',\n",
    "                     'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n",
    "\n",
    "\n",
    "# Remove columns with only one unique value\n",
    "for col in [col for col in df.columns if col not in columns_to_remove]:\n",
    "    if df.select(col).distinct().count() == 1:\n",
    "        print(\"Column '{}' has only one unique value\".format(col))\n",
    "        columns_to_remove.append(col)\n",
    "        \n",
    "# Select columns that are NOT in the 'columns_to_remove' list\n",
    "df = df.select([col for col in df.columns if col not in columns_to_remove])\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "categorical_cols = ['UniqueCarrier', 'Origin', 'Dest']\n",
    "numerical_cols = [x for x in df.columns if x not in categorical_cols]\n",
    "\n",
    "target_var = 'ArrDelay'\n",
    "\n",
    "# Remove the target variable 'ArrDelay' from the lists\n",
    "if target_var in numerical_cols:\n",
    "    numerical_cols.remove(target_var)\n",
    "if target_var in categorical_cols:\n",
    "    categorical_cols.remove(target_var)\n",
    "    \n",
    "# Print the lists\n",
    "print(\"Numerical Columns:\", numerical_cols)\n",
    "print(\"Categorical Columns:\", categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+-------+----------+----------+---------+--------------+--------+--------+--------+---------+---------------------+--------------+------------+\n",
      "|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|CRSArrTime|FlightNum|CRSElapsedTime|ArrDelay|DepDelay|Distance|Cancelled|UniqueCarrier_encoded|Origin_encoded|Dest_encoded|\n",
      "+-----+----------+---------+-------+----------+----------+---------+--------------+--------+--------+--------+---------+---------------------+--------------+------------+\n",
      "|   10|        14|        3|    741|       730|       849|     1451|            79|      23|      11|     447|        0|                 11.0|          28.0|         5.0|\n",
      "|   10|        15|        4|    729|       730|       849|     1451|            79|      14|      -1|     447|        0|                 11.0|          28.0|         5.0|\n",
      "|   10|        17|        6|    741|       730|       849|     1451|            79|      29|      11|     447|        0|                 11.0|          28.0|         5.0|\n",
      "|   10|        18|        7|    729|       730|       849|     1451|            79|      -2|      -1|     447|        0|                 11.0|          28.0|         5.0|\n",
      "|   10|        19|        1|    749|       730|       849|     1451|            79|      33|      19|     447|        0|                 11.0|          28.0|         5.0|\n",
      "|   10|        21|        3|    728|       730|       849|     1451|            79|      -1|      -2|     447|        0|                 11.0|          28.0|         5.0|\n",
      "|   10|        22|        4|    728|       730|       849|     1451|            79|       3|      -2|     447|        0|                 11.0|          28.0|         5.0|\n",
      "|   10|        23|        5|    731|       730|       849|     1451|            79|      13|       1|     447|        0|                 11.0|          28.0|         5.0|\n",
      "|   10|        24|        6|    744|       730|       849|     1451|            79|      19|      14|     447|        0|                 11.0|          28.0|         5.0|\n",
      "|   10|        25|        7|    729|       730|       849|     1451|            79|       2|      -1|     447|        0|                 11.0|          28.0|         5.0|\n",
      "|   10|        26|        1|    735|       730|       849|     1451|            79|      15|       5|     447|        0|                 11.0|          28.0|         5.0|\n",
      "|   10|        28|        3|    741|       725|       855|     1451|            90|      24|      16|     447|        0|                 11.0|          28.0|         5.0|\n",
      "|   10|        29|        4|    742|       725|       855|     1451|            90|      11|      17|     447|        0|                 11.0|          28.0|         5.0|\n",
      "|   10|        31|        6|    726|       725|       855|     1451|            90|      -7|       1|     447|        0|                 11.0|          28.0|         5.0|\n",
      "|   10|         1|        4|    936|       915|      1001|     1451|            46|      34|      21|     192|        0|                 11.0|           5.0|        62.0|\n",
      "|   10|         2|        5|    918|       915|      1001|     1451|            46|      16|       3|     192|        0|                 11.0|           5.0|        62.0|\n",
      "|   10|         3|        6|    928|       915|      1001|     1451|            46|      36|      13|     192|        0|                 11.0|           5.0|        62.0|\n",
      "|   10|         4|        7|    914|       915|      1001|     1451|            46|       2|      -1|     192|        0|                 11.0|           5.0|        62.0|\n",
      "|   10|         5|        1|   1042|       915|      1001|     1451|            46|      88|      87|     192|        0|                 11.0|           5.0|        62.0|\n",
      "|   10|         6|        2|    934|       915|      1001|     1451|            46|      23|      19|     192|        0|                 11.0|           5.0|        62.0|\n",
      "+-----+----------+---------+-------+----------+----------+---------+--------------+--------+--------+--------+---------+---------------------+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Label encode categorical columns\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_encoded\") for col in categorical_cols]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df_encoded = pipeline.fit(df).transform(df)\n",
    "\n",
    "# Drop the original categorical columns\n",
    "df_encoded = df_encoded.drop(*categorical_cols)\n",
    "\n",
    "# Show the DataFrame with label-encoded categorical columns\n",
    "df_encoded.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close context\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
